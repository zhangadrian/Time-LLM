{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661b2c1b60846e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T04:41:34.685304Z",
     "start_time": "2024-12-13T04:41:29.966135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniforge3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/miniforge3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/root/miniforge3/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/root/miniforge3/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_term_forecast\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "from accelerate import DistributedDataParallelKwargs\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import Autoformer, DLinear, TimeLLM, TimeLLM_lora_bnb\n",
    "\n",
    "from data_provider.data_factory import data_provider\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "from utils.tools import del_files, EarlyStopping, adjust_learning_rate, vali, load_content\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Task parameters\n",
    "        self.task_name = 'long_term_forecast'  # options: [long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]\n",
    "        self.is_training = 1\n",
    "        self.model_id = 'test'\n",
    "        self.model_comment = 'none'\n",
    "        self.model = 'TimeLLM'  # options: [Autoformer, DLinear]\n",
    "        self.seed = 2021\n",
    "\n",
    "        # Data loader parameters\n",
    "        self.data = 'ETTm1'  # dataset type\n",
    "        self.root_path = \"../data/dataset/ETT-small\"  # root path of the data file\n",
    "        self.data_path = 'ETTm1.csv'  # data file\n",
    "        self.features = 'M'  # options: [M, S, MS]\n",
    "        self.target = 'OT'  # target feature in S or MS task\n",
    "        self.loader = 'modal'  # dataset type\n",
    "        self.freq = 'h'  # options: [s, t, h, d, b, w, m]\n",
    "        self.checkpoints = './checkpoints/'  # location of model checkpoints\n",
    "\n",
    "        # Forecasting task parameters\n",
    "        self.seq_len = 96  # input sequence length\n",
    "        self.label_len = 48  # start token length\n",
    "        self.pred_len = 96  # prediction sequence length\n",
    "        self.seasonal_patterns = 'Monthly'  # subset for M4\n",
    "\n",
    "        # Model definition parameters\n",
    "        self.enc_in = 7  # encoder input size\n",
    "        self.dec_in = 7  # decoder input size\n",
    "        self.c_out = 7   # output size\n",
    "        self.d_model = 16  # dimension of model\n",
    "        self.n_heads = 8   # num of heads\n",
    "        self.e_layers = 2   # num of encoder layers\n",
    "        self.d_layers = 1   # num of decoder layers\n",
    "        self.d_ff = 32      # dimension of fcn\n",
    "        self.moving_avg = 25   # window size of moving average\n",
    "        self.factor = 1      # attention factor\n",
    "        self.dropout = 0.1   # dropout rate\n",
    "        self.embed = 'timeF'   # time features encoding options: [timeF, fixed, learned]\n",
    "        self.activation = 'gelu'   # activation function\n",
    "        self.output_attention = False   # whether to output attention in encoder\n",
    "        self.patch_len = 16   # patch length\n",
    "        self.stride = 8       # stride length\n",
    "        self.prompt_domain = 0   # prompt domain (if applicable)\n",
    "        self.llm_model = 'LLAMA'   # LLM model options: [LLAMA, GPT2, BERT]\n",
    "        self.llm_dim = 4096    # LLM model dimension\n",
    "\n",
    "        # Optimization parameters\n",
    "        self.num_workers = 10   # data loader num workers\n",
    "        self.itr = 1            # experiments times\n",
    "        self.train_epochs = 10   # train epochs\n",
    "        self.align_epochs = 10    # alignment epochs\n",
    "        self.batch_size = 16     # batch size of train input data\n",
    "        self.eval_batch_size = 8   # batch size of model evaluation\n",
    "        self.patience = 10       # early stopping patience\n",
    "        self.learning_rate = 0.0001    # optimizer learning rate\n",
    "        self.des = 'test'       # experiment description\n",
    "        self.loss = 'MSE'       # loss function options: ['MSE', ...]\n",
    "        self.lradj = 'type1'    # adjust learning rate type options: ['type1', ...]\n",
    "        self.pct_start = 0.2     # pct_start for learning rate adjustment\n",
    "        self.use_amp = False      # use automatic mixed precision training\n",
    "        self.llm_layers = 6       # number of LLM layers\n",
    "        self.percent = 100\n",
    "        self.model_name = \"meta-llama/Llama-3.1-8B\"\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# 使用示例：\n",
    "args = Args()\n",
    "print(args.task_name)           # 输出: long_term_forecast\n",
    "print(args.batch_size)\n",
    "ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "deepspeed_plugin = DeepSpeedPlugin(hf_ds_config='./ds_config_zero2.json')\n",
    "accelerator = Accelerator(kwargs_handlers=[ddp_kwargs], deepspeed_plugin=deepspeed_plugin)\n",
    "setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_{}_{}'.format(\n",
    "    args.task_name,\n",
    "    args.model_id,\n",
    "    args.model,\n",
    "    args.data,\n",
    "    args.features,\n",
    "    args.seq_len,\n",
    "    args.label_len,\n",
    "    args.pred_len,\n",
    "    args.d_model,\n",
    "    args.n_heads,\n",
    "    args.e_layers,\n",
    "    args.d_layers,\n",
    "    args.d_ff,\n",
    "    args.factor,\n",
    "    args.embed,\n",
    "    args.des, 0)# 输出: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181395f5-1cda-48fe-b709-3ae7599a4c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "q_config = BitsAndBytesConfig(load_in_4bit=False,\n",
    "                                bnb_4bit_quant_type='nf4',\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_compute_dtype=torch.float16\n",
    "                                )\n",
    "from transformers.utils import is_bitsandbytes_available\n",
    "is_bitsandbytes_available()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca68fa4aaeab228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T04:42:09.824481Z",
     "start_time": "2024-12-13T04:41:34.747901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe55ebee48c4a0f8a51d76bf31a5aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_token = \"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\"  #Put your own HF token here, do not publish it\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login directly with your Token (remember not to share this Token publicly)\n",
    "login(token=hf_token)\n",
    "import os\n",
    "device = args.device\n",
    "model = TimeLLM_lora_bnb.Model(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d49deb76-e900-4057-9f30-1c3ac48816b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e285794f2a67ff72",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-13T04:42:09.883014Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15036 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 1 - Zero grad: 0.0013s\n",
      "step 1 2 - Data to device: 0.0012s\n",
      "step 1 3 - Prepare decoder input: 0.0003s\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Half and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miter_count\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 4 - Model forward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/FinAI/Time-LLM/models/TimeLLM_lora_bnb.py:117\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_enc, x_mark_enc, x_dec, x_mark_dec, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_term_forecast\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_term_forecast\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m         dec_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mark_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_dec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_mark_dec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dec_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :]\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/FinAI/Time-LLM/models/TimeLLM_lora_bnb.py:159\u001b[0m, in \u001b[0;36mModel.forecast\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec)\u001b[0m\n\u001b[1;32m    156\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m    157\u001b[0m prompt_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_model\u001b[38;5;241m.\u001b[39mget_input_embeddings()(prompt\u001b[38;5;241m.\u001b[39mto(x_enc\u001b[38;5;241m.\u001b[39mdevice))  \u001b[38;5;66;03m# (batch, prompt_token, dim)\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m source_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    161\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m x_enc\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    162\u001b[0m enc_out, n_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embedding(x_enc)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Half and Float"
     ]
    }
   ],
   "source": [
    "# 假设其他必要的导入和EarlyStopping, adjust_learning_rate, vali, data_provider等函数已经定义\n",
    "\n",
    "print(device)\n",
    "train_data, train_loader = data_provider(args, 'train')\n",
    "vali_data, vali_loader = data_provider(args, 'val')\n",
    "test_data, test_loader = data_provider(args, 'test')\n",
    "early_stopping = EarlyStopping(accelerator=accelerator, patience=args.patience)\n",
    "path = os.path.join(args.checkpoints, setting + '-' + args.model_comment)  # unique checkpoint saving path\n",
    "args.content = load_content(args)\n",
    "if not os.path.exists(path) and accelerator.is_local_main_process:\n",
    "    os.makedirs(path)\n",
    "time_now = time.time()\n",
    "train_steps = len(train_loader)\n",
    "model_optim = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer=model_optim,\n",
    "            steps_per_epoch=train_steps,\n",
    "            pct_start=args.pct_start,\n",
    "            epochs=args.train_epochs,\n",
    "            max_lr=args.learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "mae_metric = nn.L1Loss()\n",
    "\n",
    "model.train()\n",
    "epoch_time = time.time()\n",
    "epoch = 0\n",
    "\n",
    "iter_count = 0\n",
    "train_loss = []\n",
    "\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(tqdm(train_loader)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model_optim.zero_grad()\n",
    "    print(f\"step {iter_count + 1} 1 - Zero grad: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float().to(device)\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "    print(f\"step {iter_count + 1} 2 - Data to device: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float().to(device)\n",
    "    dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1).float().to(device)\n",
    "    print(f\"step {iter_count + 1} 3 - Prepare decoder input: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    if args.output_attention:\n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "    else:\n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    print(f\"step {iter_count + 1} 4 - Model forward: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    f_dim = -1 if args.features == 'MS' else 0\n",
    "    outputs = outputs[:, -args.pred_len:, f_dim:]\n",
    "    batch_y = batch_y[:, -args.pred_len:, f_dim:]\n",
    "    loss = criterion(outputs, batch_y)\n",
    "    train_loss.append(loss.item())\n",
    "    print(f\"step {iter_count + 1} 5 - Calculate loss: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"\\titers: {i + 1}, epoch: {epoch + 1} | loss: {loss.item():.7f}\")\n",
    "        speed = (time.time() - time_now) / iter_count\n",
    "        left_time = speed * ((args.train_epochs - epoch) * train_steps - i)\n",
    "        print(f'\\tspeed: {speed:.4f}s/iter; left time: {left_time:.4f}s')\n",
    "        iter_count = 0\n",
    "        time_now = time.time()\n",
    "    start_time = time.time()\n",
    "    loss.backward()\n",
    "    print(f\"step {iter_count + 1} 6 - Backward: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_optim.step()\n",
    "    print(f\"step {iter_count + 1} 7 - Optimizer step: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    adjust_learning_rate(accelerator, model_optim, scheduler, epoch + 1, args, printout=False)\n",
    "    print(f\"step {iter_count + 1} 8 - Adjust learning rate: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    scheduler.step()\n",
    "    print(f\"step {iter_count + 1} 9 - Scheduler step: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch: {epoch + 1} cost time: {time.time() - epoch_time}\")\n",
    "    train_loss = np.average(train_loss)\n",
    "    print(f\"step {iter_count + 1} 10 - Average train loss: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    vali_loss, vali_mae_loss = vali(args, accelerator, model, vali_data, vali_loader, criterion, mae_metric)\n",
    "    print(f\"step {iter_count + 1} 11 - Validation: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_loss, test_mae_loss = vali(args, accelerator, model, test_data, test_loader, criterion, mae_metric)\n",
    "    print(f\"step {iter_count + 1} 12 - Test: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f\"Epoch: {epoch + 1} | Train Loss: {train_loss:.7f} Vali Loss: {vali_loss:.7f} Test Loss: {test_loss:.7f} MAE Loss: {test_mae_loss:.7f}\")\n",
    "    early_stopping(vali_loss, model, path)\n",
    "    print(f\"step {iter_count + 1} 13 - Early stopping: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f'Updating learning rate to {scheduler.get_last_lr()[0]}')\n",
    "    print(f\"step {iter_count + 1} 14 - Learning rate updated: {time.time() - start_time:.4f}s\")\n",
    "\n",
    "    iter_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d746dbd467d219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:16:08.217351Z",
     "start_time": "2024-12-09T12:16:08.214199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.tools.EarlyStopping at 0x7fa472f83910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dcbce273c100113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:22:53.867198Z",
     "start_time": "2024-12-09T12:22:53.861857Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_parameters = []\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad is True:\n",
    "        trained_parameters.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5106f24eac05e1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T02:37:44.629116Z",
     "start_time": "2024-12-10T02:37:44.616028Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40302d4711a2f199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T03:28:24.110271Z",
     "start_time": "2024-12-10T03:28:24.099030Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4790a868db88e4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T03:28:35.634786Z",
     "start_time": "2024-12-10T03:28:35.630933Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ead040c8e88984a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T13:20:04.869084Z",
     "start_time": "2024-12-10T13:20:04.857901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf8f6218d47c3d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T14:10:04.168390Z",
     "start_time": "2024-12-10T14:09:13.110744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 1]) torch.Size([32, 144, 1]) torch.Size([32, 96, 4]) torch.Size([32, 144, 4])\n",
      "torch.Size([32, 96, 1]) torch.Size([32, 144, 1]) torch.Size([32, 96, 4]) torch.Size([32, 144, 4])\n",
      "torch.Size([32, 96, 1]) torch.Size([32, 144, 1]) torch.Size([32, 96, 4]) torch.Size([32, 144, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in tqdm(enumerate(train_loader)):\n",
    "    if i > 2: break\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float().to(device)\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "\n",
    "    print(batch_x.shape, batch_y.shape, batch_x_mark.shape, batch_y_mark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47c9ea68e0275942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T03:13:08.284452Z",
     "start_time": "2024-12-11T03:13:08.279803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f80d1f533f58bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T03:11:03.874168Z",
     "start_time": "2024-12-11T03:11:03.803550Z"
    }
   },
   "outputs": [],
   "source": [
    "dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :], dtype=torch.float32).float().to(\n",
    "                device)\n",
    "dec_inp = torch.cat([batch_y[:, :args.label_len, :].float().to(device), dec_inp], dim=1).to(\n",
    "    device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8c35a2c96d4df00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T03:11:11.973622Z",
     "start_time": "2024-12-11T03:11:11.970463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 144, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41669ebaddd86ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
